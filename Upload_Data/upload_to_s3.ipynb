{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32787765-9fe5-4761-9a85-06651f2bb958",
   "metadata": {},
   "source": [
    "### Upload train and validation Text Documents to AWS S3 for LLM Fine-Tuning with Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89888f-5d42-4e4c-9d4f-f44d747610ee",
   "metadata": {},
   "source": [
    "Create an AWS S3 Bucket\n",
    "Amazon S3 (Simple Storage Service) provides scalable object storage, and it's a foundational element for data storage in AWS. Here's how you can create an S3 bucket:\n",
    "Prerequisites\n",
    "Ensure you have an AWS account and have set up AWS CLI with the necessary permissions. We will use the session credentials from AWS Sagemaker Notebook\n",
    "Step 1: Initialize Boto3 and S3 Client\n",
    "We start by importing boto3 and setting up an S3 client. Boto3 is the AWS SDK for Python, which allows Python developers to write software that uses AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d5f1ea-cb79-42d5-a6e8-005d46b96c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "aws_session = boto3.Session()\n",
    "s3_client = aws_session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498b9511-2d6c-485a-873a-8eb5e2bc8523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bucket_name = 'rany-domain-adaptation-training-sagemaker'\n",
    "s3_client.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98544d4-2b6f-4bc4-adb2-55b671681879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train.txt' has been uploaded to 'rany-domain-adaptation-training-sagemaker' as 'domain_adaptation/gptj6b/train/train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Upload the train file\n",
    "train_object_name = 'domain_adaptation/gptj6b/train/train.txt'\n",
    "train_file_name = 'train.txt'\n",
    "try:\n",
    "    with open(train_file_name, 'rb') as file:\n",
    "        s3_client.upload_fileobj(file, bucket_name, train_object_name)  # Pass 'file' instead of 'file_name'\n",
    "    print(f\"'{train_file_name}' has been uploaded to '{bucket_name}' as '{train_object_name}'.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580be15-f47a-4393-b135-71c1db1568a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40aba105-047e-4bb9-b963-a7de575f5fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'validation.txt' has been uploaded to 'rany-domain-adaptation-training-sagemaker' as 'domain_adaptation/gptj6b/validation/validation.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Upload the validation file\n",
    "validation_object_name = 'domain_adaptation/gptj6b/validation/validation.txt'\n",
    "validation_file_name = 'validation.txt'\n",
    "try:\n",
    "    with open(validation_file_name, 'rb') as file:\n",
    "        s3_client.upload_fileobj(file, bucket_name, validation_object_name)  # Pass 'file' instead of 'file_name'\n",
    "    print(f\"'{validation_file_name}' has been uploaded to '{bucket_name}' as '{validation_object_name}'.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b78dc-63d5-4a9d-87ca-b86576fc0f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb34dd7-f72a-4807-a39b-bd4fd7cf89a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain_adaptation/gptj6b/train/train.txt\n",
      "domain_adaptation/gptj6b/validation/validation.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the prefix (folder path)\n",
    "prefix = 'domain_adaptation/gptj6b/'\n",
    "\n",
    "# List objects within the specified prefix\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "# Check if 'Contents' key is in the response (it's not present if the directory is empty or does not exist)\n",
    "if 'Contents' in response:\n",
    "    # Iterate through the objects in the response and print their names\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No objects found in the specified path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f2348-ff97-40dc-9f93-e0d3d0f65476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48c20c97-834d-4309-80ff-62a332350811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-textgeneration1-gpt-j-6b' with wildcard version identifier '1.*'. You can pin to version '1.3.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "training_instance_type = \"ml.g5.12xlarge\"\n",
    "model_id, model_version = \"huggingface-textgeneration1-gpt-j-6b\", \"1.*\"\n",
    "\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a89d5f-07bf-4c13-a696-93177546ee3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "print(train_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c41ae79-b384-4eed-9b72-f3718eaaaeae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import script_uris\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "\n",
    "print(train_source_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4184aff7-354b-4e01-8eac-a5d9517b4cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz to sourcedir.tar.gz\n",
      "Extracted sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Specify the bucket and object key\n",
    "bucket_name = 'jumpstart-cache-prod-us-east-1'\n",
    "object_key = 'source-directory-tarballs/huggingface/transfer_learning/textgeneration1/prepack/v1.2.0/sourcedir.tar.gz'\n",
    "local_file_name = 'sourcedir.tar.gz'\n",
    "\n",
    "# Download the file from S3\n",
    "s3_client.download_file(bucket_name, object_key, local_file_name)\n",
    "print(f\"Downloaded {object_key} to {local_file_name}\")\n",
    "\n",
    "# Unzip the file\n",
    "with tarfile.open(local_file_name, \"r:gz\") as tar:\n",
    "    tar.extractall()\n",
    "    print(f\"Extracted {local_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578a624-6726-42b2-8671-298db1db4580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
